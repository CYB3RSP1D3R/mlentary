%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.8. on overfitting  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{on overfitting}
        In the Bayesian framework, we optimistically assume that our model is
        ``correct'' and that the ``true'' posterior over parameters is
        $$
            p(w|y;x) = p(y|w;x) p(w) / Z_x
        $$
        a normalized product of likelihood and prior.
        %
        Therefore, our optimal guess for a new prediction is:
        $$
            p(y_\star;x_\star, x)
            = \sum_w p(y_\star|w;x_\star) p(y|w;x) p(w) / Z_x
        $$

        For computational tractability, we typically approximate the posterior
        over hypotheses by a point mass at the posterior's mode
        $\text{argmax}_{w^\prime} p(w^\prime|y;x)$:
        $$
            p(w|y,x) \approx \delta(w - w^\star(y,x))
            \quad\quad
            w^\star(y,x)=\text{argmax}_{w^\prime} p(w^\prime|y;x)
        $$
        Then
        $$
            p(y_\star;x_\star, x)
            \approx p(y_\star|w^\star(y,x);x_\star)
        $$

        What do we lose in this approximation?

        \attnsam{$\Ee$ and $\max$ do not commute}

        \attnsam{PICTURE: ``bowtie'' vs ``pipe''}

        \attnsam{BIC for relevant variables}


        %\attnsam{point estimates vs bayesian decision theory}

        %\attnsam{interpolation does not imply overfitting}


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.9. log priors and bayes  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{log priors and bayes}
        \attnsam{fill in computation and bases}
        \attnsam{visual illustration of how choice of L2 dot product matters}
        \attnsam{$\ell^p$ regularization; sparsity}
        \attnsam{eye regularization example!}
        \attnsam{TODO: rank as a prior (for multioutput models)}

        %The so-called $\ell^p$ priors are popular.  For $1\leq p<\infty$,
        %these are defined by:
        For $1\leq p\leq \infty$ and $1\leq q\leq \infty$ we can consider this prior:\bovinenote{%
          To define the cases $p=\infty$ or $q=\infty$ we take limits.
          To define the case $p=\infty=q$ we take limits while maintaining $p=q$.
        }
        $$
            p(w) \propto \exp\left(-\left(\sum_i |\lambda w_i|^p\right)^{q/p}\right)
        $$
        For $q=p$ this decomposes as a sum and thus has each coordinate
        independent.  Whereas $q$ limits outliers, $p$ controls the shape of
        level curves.  Small $q$ makes large vectors more probable and
        small $p$ makes it more probable that the entries within a vector will
        be of very different sizes.
        \newcommand{\priors}[1]{\includegraphics[width=2.9cm]{priors/yo-#1}}
        \newcommand{\smarsh}[1]{\vspace{0.125cm}\smash{\parbox[c]{3cm}{#1}}\vspace{0.525cm}}
        \begin{table}
          \centering
          \begin{tabular}{m{1.1cm}SSS}%
                                & $q=1$                 & $q=2$                 & $q=\infty$              \\%
            \smarsh{     $p=1$} &\smarsh{\priors{1-1}}  &\smarsh{\priors{1-2}}  &\smarsh{\priors{1-inf}}  \\%
            \smarsh{     $p=2$} &\smarsh{\priors{2-1}}  &\smarsh{\priors{2-2}}  &\smarsh{\priors{2-inf}}  \\%
            \smarsh{$p=\infty$} &\smarsh{\priors{inf-1}}&\smarsh{\priors{inf-2}}&\smarsh{\priors{inf-inf}}\\%
          \end{tabular}
        \end{table}

        %\begin{table}
        %    \centering
        %    \begin{tabular}{ccccccc}
        %        p         &       q         &  sample A          &  sample B          &   shape       & indep.?       & outliers    \\\hline% sample A            sample B
        %        $1     $  &       $1$       & $( 0.5,-0.1, 0.7)$ & $(14.4,-0.9,-0.9)$ & octahedron    & $\checkmark$  & many        \\      %$( 0.6, 0.1, 0.9)$  $( 1.6, 0.1, 0.1)$
        %        $1     $  &       $2$       & $( 0.6,-0.1, 0.9)$ & $( 4.8,-0.3,-0.3)$ & octahedron    &               & few         \\      %$( 0.6, 0.1, 0.9)$  $( 1.6, 0.1, 0.1)$
        %        $1     $  &       $\infty$  & $( 0.7,-0.1, 1.1)$ & $( 1.6,-0.1,-0.1)$ & octahedron    &               & none        \\      %$( 0.6, 0.1, 0.9)$  $( 1.6, 0.1, 0.1)$
        %        $2     $  &       $1$       & $( 0.3,-0.2, 0.8)$ & $(13.5,-7.2,-2.7)$ & sphere        &               & many        \\      %$( 0.4, 0.2, 1.0)$  $( 1.5, 0.8, 0.3)$
        %        $2     $  &       $2$       & $( 0.4,-0.2, 1.0)$ & $( 4.5,-2.4,-0.9)$ & sphere        & $\checkmark$  & few         \\      %$( 0.4, 0.2, 1.0)$  $( 1.5, 0.8, 0.3)$
        %        $2     $  &       $\infty$  & $( 0.5,-0.2, 1.2)$ & $( 1.5,-0.8,-0.3)$ & sphere        &               & none        \\      %$( 0.4, 0.2, 1.0)$  $( 1.5, 0.8, 0.3)$
        %        $\infty$  &       $1$       & $( 0.4,-0.2, 0.7)$ & $( 9.0,-8.1,-7.2)$ & cube          &               & many        \\      %$( 0.5, 0.3, 0.9)$  $( 1.0, 0.9, 0.8)$
        %        $\infty$  &       $2$       & $( 0.5,-0.3, 0.9)$ & $( 3.0,-2.7,-2.4)$ & cube          &               & few         \\      %$( 0.5, 0.3, 0.9)$  $( 1.0, 0.9, 0.8)$
        %        $\infty$  &       $\infty$  & $( 0.6,-0.4, 1.1)$ & $( 1.0,-0.9,-0.8)$ & cube          & $\checkmark$  & none        \\      %$( 0.5, 0.3, 0.9)$  $( 1.0, 0.9, 0.8)$
        %    \end{tabular}
        %\end{table}
        %\begin{description}
        %    \item[$(p,q)=(1     ,1)$ --- indep laplacian        ]
        %    \item[$(p,q)=(1     ,2)$ ---                        ]
        %    \item[$(p,q)=(2     ,1)$ ---                        ]
        %    \item[$(p,q)=(2     ,2)$ --- indep\&radial gaussian ]
        %    \item[$(p,q)=(\infty,1)$ ---                        ]
        %    \item[$(p,q)=(\infty,2)$ ---planckian               ]
        %\end{description}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.10. hierarchy, mixtures, transfer  ~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{hierarchy, mixtures, transfer}
        \attnsam{k-fold cross validation}
        %\attnsam{dimension-based generalization bound}
        \attnsam{bayesian information criterion}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.11. estimating generalization  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{estimating generalization}
        \attnsam{k-fold cross validation}
        \attnsam{dimension-based generalization bound}
        \attnsam{bayesian information criterion}

      \newpage
    \samsection{3. model selection}
      \samquote{
        All human beings have three lives: public, private, and secret.
      }{gabriel garc\`ia marquez}


