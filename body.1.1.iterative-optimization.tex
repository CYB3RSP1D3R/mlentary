    \newpage
    \samsection{1. iterative optimization}
      \samquote{
        Hey Jude, don't make it bad \\
        Take a sad song and make it better \\
        Remember to let her under your skin \\
        Then you'll begin to make it \\
        Better, better, better, better, better, better, ...
      }{paul mccartney, john lennon}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.4. stochastic gradient descent  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{(stochastic) gradient descent}
        We have a collection $\hH$ of candidate patterns together with a
        function $1-\Ein$ that tells us how good a candidate is.\marginnote{%
          $\leftarrow$ We view $1-\Ein$ as an estimate of our actual notion of
          ``good'': $1-\Eout$.
        }
        %
        In \S A we found a nearly best candidate by brute-force search over all
        of $\hH$; this doesn't scale to the general case, where $\hH$ is
        intractably large.
        %
        So: \emph{what's a faster algorithm to find a nearly best candidate?}

        A common idea is to start arbitrarily with some $h_0\in \hH$ and
        repeatedly improve to get $h_1, h_2, \cdots$.  Two questions are:
        \emph{how do we select $h_{t+1}$ in terms of $h_t$}?  And \emph{how do
        we know when to stop}?  We'll discuss termination conditions later
        --- for now, let's agree to stop at $h_{10000}$.

        As for selecting a next candidate, we'd like to use more detailed
        information on $h_t$'s inadequacies to inform our proposal $h_{t+1}$.
        Intuitively, if $h_t$ misclassifies a particular $(x_n, y_n) \in \sS$,
        then we'd like $h_{t+1}$ to be like $h_t$ but nudged a bit in the
        direction of accurately classifying $(x_n, y_n)$.

        Derivatives measure how changing a parameter a bit affects a result.
        So let's
        %
        \attnsam{FILL IN FOR PROBABILITIES (LOGISTIC) MODEL}

        This is the idea of \textbf{gradient descent}.
        \attnsam{MOTIVATE AND GIVE PSEUDOCODE FOR STOCHASTIC GD}

        Given a list of training examples, a probability model, and a
        hypothesis $\vec w$, we can compute $\vec w$'s asserted probability
        that the training $x$s correspond to the training $y$s.  It seems
        reasonable to choose $\vec w$ so that this probability is maximal.
        This method is called \textbf{maximum likelihood estimation (MLE)}.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.5. logistic models  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{logistic models} %``soft''

        The probability of a bunch of independent observations is the same as
        the product of probabilities of the observations.  Taking logarithms
        turns products into more manageable sums.  And --- this is a historical
        convention --- we further flip signs $\pm$ to turn maximization to
        minimization.
        %
        After this translation, MLE with the logistic model means finding $\vec
        w$ that minimizes
        $$
          \sum_i \log_2(1+\exp(-y_i\vec w\cdot \vec x_i))
          =
          \sum_i \text{softplus}(-y_i\vec w\cdot \vec x_i)
        $$
        Here, $\text{softplus}$ is our name for the function that sends
        $z$ to $\log_2(1+\exp(z))$.

        \attnsam{mention convexity and convergence?}
        \attnsam{show trajectory in weight space over time -- see how certainty
        degree of freedom is no longer redundant? (``markov'')}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.6. humble models  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \newpage
      \sampassage{humble models}
        Let's modify logistic classification to allow for \emph{unknown
        unknowns}. We'll do this by allowing a classifier to allot probability
        mass not only among labels in $\yY$ but also to a special class $\star$
        that means ``no comment'' or ``alien input''.  A logistic classifier
        always sets $\Pp_{\sfy|\sfx}[\star|x] = 0$.
        %
        Other probability models may put nonzero mass on ``no comment'';
        different models give different learning programs.  Here are four
        models we might consider:
        \newcommand{\zp}{u^{\!+\!}}
        \newcommand{\zm}{u^{\!-\!}}
        \begin{table}
          \centering
          \small
          \vspace{-0.3cm}
          \begin{tabular}{RCCCC}
                                        & \textsc{logistic}     & \textsc{perceptron}       & \textsc{svm}              & \textsc{gauss-gen}        \\\hline %& \textsc{gauss}
            \Pp_{\sfy|\sfx}[-1| x]      & \zm/(\zm+\zp)         &\zm\cdot(\zm\wedge\zp)/2   &\zm\cdot(\zm/e\wedge\zp)/2 &\zm\cdot\text{bumps}       \\       %&\zm \cdot \epsilon e^{-d^2/4}
            \Pp_{\sfy|\sfx}[+1| x]      & \zp/(\zm+\zp)         &\zp\cdot(\zm\wedge\zp)/2   &\zp\cdot(\zm\wedge\zp/e)/2 &\zp\cdot\text{bumps}       \\       %&\zp \cdot \epsilon e^{-d^2/4}
            \Pp_{\sfy|\sfx}[\star| x]   & 1 - ~\text{above}=0   &1 - ~\text{above}          &1 - ~\text{above}          &1 - ~\text{above}          \\\hline %&1 - ~\text{above}
            %                                                                                                                                                %
            \text{loss name}            &\text{softplus}(\cdot) &\text{srelu}(\cdot)        &\text{hinge}(\cdot)        &\text{quad}(\cdot)         \\       %&\text{parab}(\cdot)
            \text{formula}              &\log_2(1+e^{(\cdot)})&\max(1,\cdot)+1            &\max(1,\cdot+1)            & ??                        \\       %&(\cdot+1)^2
            \text{update}               &1/(1+e^{+yd})        &\text{step}(-yd)           &\text{step}(1-yd)          & ??                        \\\hline %&2(1-yd)
            %                                                                                                                                                %
            \text{outliers}             &\text{robust-ish}      &\text{robust}              &\text{robust}              &\text{vulnerable}          \\       %&\text{vulnerable}
            \text{inliers}              &\text{sensitive}       &\text{blind}               &\text{sensitive}           &\text{blind-ish}           \\       %&\text{blind}
            \text{humility}             &\text{low}             &\text{low}                 &\text{high-ish}            &\text{high}                \\ 
            \text{acc bnd}              &\text{good}            &\text{bad}                 &\text{good}                &\text{good-ish}
            %\text{humility}             &\text{low}             &\text{medium}              &\text{high}                \\             % &\text{high}
            % TODO: split outliers/inliers by good or bad (erroneously classified or not?)  so 4 rows instead of 2?
          \end{tabular}
          \caption{%
            \textbf{Four popular models for binary classification.}
            %
            \textbf{Top rows:} Modeled chance given $x$ that $y=+1$ or $-1$ or
            $\star$.  We use $d = \vec w\cdot \vec x$, $u^{\!\pm\!}$ =
            $e^{\!\pm\! d/2}$, $a\wedge b = \min(a,b)$ to save ink.  And
            $\text{bumps}=(\phi(d-1)+\phi(d+1))/2$ with $\phi(\cdot)$ the
            standard normal density function.
            %
            \textbf{Middle rows:} neg-log-likelihood losses.
            %that arise when maximize likelihood using these models.
            An SGD step looks like
            $
              \vec w_{t+1} = \vec w_t + (\eta \cdot \text{update} \cdot y \vec x)
            $.
            %
            \textbf{Bottom rows:} All models respond to misclassifications.
            But are they robust
            to well-classified outliers?
            Sensitive to well-classified inliers?
            \par\noindent
            \attn{Exercise}: {
               Fill in the ??s in the rightmost column of the table above.
            }
          }
          \vspace{+0.3cm}
        \end{table}

        MLE with the perceptron model, svm model, or gauss-gen model minimizes
        the same thing, but with
        $\text{srelu}(z) = \text{max}(0,z)+1$,
        $\text{hinge}(z) = \text{max}(0,z+1)$, or
        $\text{quad}(z) = \cdots$
        instead of $\text{softplus}(z)$.\bcirc\marginnote{%
          \blarr Other models we might try will induce other substitutes for softplus.
          E.g.  $z\mapsto \text{hinge}(z)^2$ or $z\mapsto
          \text{avg}(z, \sqrt{z^2+4})$.
        }
        %https://www.desmos.com/calculator/3yak0ozell

        Two essential properties of $\text{softplus}$ are that:
        (a) it is convex and
        (b) it upper bounds the step function.
        Note that $\text{srelu}$, $\text{hinge}$, and $\text{quad}$ also enjoy
        these properties.  Property (a) ensures that the optimization problem
        is relatively easy --- under mild conditions, gradient descent is
        guaranteed to find a global minimum.  By property (b), the total loss
        on a training set upper bounds the rate of erroneous classification on
        that training set.  So loss is a \emph{surrogate} for (in)accuracy: if
        the minimized loss is nearly zero, then the training accuracy is nearly
        $100\%$.\marginnote{%
          The perceptron satisfies (b) in a trivial way that yields a trivial
          bound of $100\%$ on the error rate.
        }

        \attnsam{training behavior!!}
        \attnsam{response to outliers}
        \attnsam{support vectors}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~  2.7. pictures of training  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      \sampassage{pictures of training}
        \par\attnsam{}
        \par\attnsam{}
        \par\attnsam{test vs train curves: overfitting}
        \par\attnsam{random featurization: double descent}

    \newpage
    \samsection{2. priors and generalization}
      \samquote{
        A child's education should begin at least 100 years before [they are]
        born.
      }{oliver wendell holmes jr}


